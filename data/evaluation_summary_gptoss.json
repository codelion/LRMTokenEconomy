{
  "one_plus_one": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 2": 1.0
      },
      "avg_character_count_output": 1.2,
      "avg_character_count_reasoning": 195.4,
      "avg_character_count_completion": 196.6,
      "avg_tokens_output": 13.2,
      "avg_tokens_reasoning": 49.2,
      "avg_tokens_completions": 62.4
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 2": 0.8,
        "Answer \u00e8s 2": 0.2
      },
      "avg_character_count_output": 7.4,
      "avg_character_count_reasoning": 144.2,
      "avg_character_count_completion": 151.6,
      "avg_tokens_output": 14.6,
      "avg_tokens_reasoning": 36.6,
      "avg_tokens_completions": 51.2
    }
  },
  "bridge_torch_easy_10m": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer suggests all four people crossing together in 10 minutes": 1.0
      },
      "avg_character_count_output": 490.4,
      "avg_character_count_reasoning": 1960.0,
      "avg_character_count_completion": 2450.4,
      "avg_tokens_output": 163.4,
      "avg_tokens_reasoning": 497.0,
      "avg_tokens_completions": 660.4
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer suggests all four people crossing together in 10 minutes": 1.0
      },
      "avg_character_count_output": 271.4,
      "avg_character_count_reasoning": 2647.8,
      "avg_character_count_completion": 2919.2,
      "avg_tokens_output": 68.4,
      "avg_tokens_reasoning": 673.6,
      "avg_tokens_completions": 742.0
    }
  },
  "AIME2023II_P1": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 220": 1.0
      },
      "avg_character_count_output": 565.4,
      "avg_character_count_reasoning": 1034.6,
      "avg_character_count_completion": 1600.0,
      "avg_tokens_output": 420.8,
      "avg_tokens_reasoning": 268.0,
      "avg_tokens_completions": 688.8
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 220": 1.0
      },
      "avg_character_count_output": 846.0,
      "avg_character_count_reasoning": 602.8,
      "avg_character_count_completion": 1448.8,
      "avg_tokens_output": 493.8,
      "avg_tokens_reasoning": 151.4,
      "avg_tokens_completions": 645.2
    }
  },
  "AIME2023II_P1_mod": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 660": 1.0
      },
      "avg_character_count_output": 557.8,
      "avg_character_count_reasoning": 889.4,
      "avg_character_count_completion": 1447.2,
      "avg_tokens_output": 411.4,
      "avg_tokens_reasoning": 227.2,
      "avg_tokens_completions": 638.6
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 660": 1.0
      },
      "avg_character_count_output": 509.0,
      "avg_character_count_reasoning": 592.6,
      "avg_character_count_completion": 1101.6,
      "avg_tokens_output": 369.2,
      "avg_tokens_reasoning": 149.0,
      "avg_tokens_completions": 518.2
    }
  },
  "AIME2025I_P2_modified": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 41": 1.0
      },
      "avg_character_count_output": 871.0,
      "avg_character_count_reasoning": 3521.2,
      "avg_character_count_completion": 4392.2,
      "avg_tokens_output": 800.8,
      "avg_tokens_reasoning": 927.6,
      "avg_tokens_completions": 1728.4
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 41": 1.0
      },
      "avg_character_count_output": 1130.6,
      "avg_character_count_reasoning": 3087.2,
      "avg_character_count_completion": 4217.8,
      "avg_tokens_output": 1061.6,
      "avg_tokens_reasoning": 798.2,
      "avg_tokens_completions": 1859.8
    }
  },
  "AIME2025I_Problem_2": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 49": 1.0
      },
      "avg_character_count_output": 845.0,
      "avg_character_count_reasoning": 3049.2,
      "avg_character_count_completion": 3894.2,
      "avg_tokens_output": 814.8,
      "avg_tokens_reasoning": 795.4,
      "avg_tokens_completions": 1610.2
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 49": 1.0
      },
      "avg_character_count_output": 849.2,
      "avg_character_count_reasoning": 1690.4,
      "avg_character_count_completion": 2539.6,
      "avg_tokens_output": 690.0,
      "avg_tokens_reasoning": 432.8,
      "avg_tokens_completions": 1122.8
    }
  },
  "capital_of_australia": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is Canberra": 1.0
      },
      "avg_character_count_output": 34.6,
      "avg_character_count_reasoning": 219.6,
      "avg_character_count_completion": 254.2,
      "avg_tokens_output": 7.8,
      "avg_tokens_reasoning": 55.4,
      "avg_tokens_completions": 63.2
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is Canberra": 1.0
      },
      "avg_character_count_output": 11.2,
      "avg_character_count_reasoning": 220.0,
      "avg_character_count_completion": 231.2,
      "avg_tokens_output": 5.8,
      "avg_tokens_reasoning": 55.4,
      "avg_tokens_completions": 61.2
    }
  },
  "train_distance": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 150 kilometers": 1.0
      },
      "avg_character_count_output": 147.2,
      "avg_character_count_reasoning": 209.2,
      "avg_character_count_completion": 356.4,
      "avg_tokens_output": 73.2,
      "avg_tokens_reasoning": 53.4,
      "avg_tokens_completions": 126.6
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 150 kilometers": 1.0
      },
      "avg_character_count_output": 22.8,
      "avg_character_count_reasoning": 180.4,
      "avg_character_count_completion": 203.2,
      "avg_tokens_output": 24.0,
      "avg_tokens_reasoning": 45.4,
      "avg_tokens_completions": 69.4
    }
  },
  "brazil_continent": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is South America": 1.0
      },
      "avg_character_count_output": 49.2,
      "avg_character_count_reasoning": 170.8,
      "avg_character_count_completion": 220.0,
      "avg_tokens_output": 13.2,
      "avg_tokens_reasoning": 43.8,
      "avg_tokens_completions": 57.0
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is South America": 1.0
      },
      "avg_character_count_output": 16.8,
      "avg_character_count_reasoning": 185.2,
      "avg_character_count_completion": 202.0,
      "avg_tokens_output": 4.8,
      "avg_tokens_reasoning": 46.6,
      "avg_tokens_completions": 51.4
    }
  },
  "leap_year_february_days": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 29": 1.0
      },
      "avg_character_count_output": 38.4,
      "avg_character_count_reasoning": 211.8,
      "avg_character_count_completion": 250.2,
      "avg_tokens_output": 16.6,
      "avg_tokens_reasoning": 53.4,
      "avg_tokens_completions": 70.0
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 29": 1.0
      },
      "avg_character_count_output": 14.4,
      "avg_character_count_reasoning": 133.2,
      "avg_character_count_completion": 147.6,
      "avg_tokens_output": 12.8,
      "avg_tokens_reasoning": 33.6,
      "avg_tokens_completions": 46.4
    }
  },
  "roses_logic": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "No, we cannot conclude that some roses are red.": 1.0
      },
      "avg_character_count_output": 529.2,
      "avg_character_count_reasoning": 604.0,
      "avg_character_count_completion": 1133.2,
      "avg_tokens_output": 119.0,
      "avg_tokens_reasoning": 156.4,
      "avg_tokens_completions": 275.4
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "No, we cannot conclude that some roses are red.": 1.0
      },
      "avg_character_count_output": 282.2,
      "avg_character_count_reasoning": 685.2,
      "avg_character_count_completion": 967.4,
      "avg_tokens_output": 67.2,
      "avg_tokens_reasoning": 177.6,
      "avg_tokens_completions": 244.8
    }
  },
  "Ice cream parlor": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 16": 1.0
      },
      "avg_character_count_output": 1089.6,
      "avg_character_count_reasoning": 2963.6,
      "avg_character_count_completion": 4053.2,
      "avg_tokens_output": 892.2,
      "avg_tokens_reasoning": 793.8,
      "avg_tokens_completions": 1686.0
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 16": 1.0
      },
      "avg_character_count_output": 1016.4,
      "avg_character_count_reasoning": 2808.4,
      "avg_character_count_completion": 3824.8,
      "avg_tokens_output": 843.4,
      "avg_tokens_reasoning": 769.2,
      "avg_tokens_completions": 1612.6
    }
  },
  "Integer pairs": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 117": 1.0
      },
      "avg_character_count_output": 1272.8,
      "avg_character_count_reasoning": 5024.6,
      "avg_character_count_completion": 6297.4,
      "avg_tokens_output": 1132.8,
      "avg_tokens_reasoning": 1321.4,
      "avg_tokens_completions": 2454.2
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer is 117": 1.0
      },
      "avg_character_count_output": 1567.8,
      "avg_character_count_reasoning": 3183.4,
      "avg_character_count_completion": 4751.2,
      "avg_tokens_output": 1117.6,
      "avg_tokens_reasoning": 835.8,
      "avg_tokens_completions": 1953.4
    }
  },
  "bridge_torch_impossible": {
    "gpt-oss-120b": {
      "average_total_score": 0.6,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer concludes that it is impossible to solve within 17 minutes": 0.6
      },
      "avg_character_count_output": 1268.6,
      "avg_character_count_reasoning": 11093.0,
      "avg_character_count_completion": 12361.6,
      "avg_tokens_output": 1274.8,
      "avg_tokens_reasoning": 2845.4,
      "avg_tokens_completions": 4120.2
    },
    "gpt-oss-20b": {
      "average_total_score": 0.4,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer concludes that it is impossible to solve within 17 minutes": 0.4
      },
      "avg_character_count_output": 701.8,
      "avg_character_count_reasoning": 6979.0,
      "avg_character_count_completion": 7680.8,
      "avg_tokens_output": 796.6,
      "avg_tokens_reasoning": 1822.0,
      "avg_tokens_completions": 2618.6
    }
  },
  "bridge_torch_easy": {
    "gpt-oss-120b": {
      "average_total_score": 0.2,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer suggests all four people crossing together in 10 minutes": 0.2
      },
      "avg_character_count_output": 1094.4,
      "avg_character_count_reasoning": 7862.0,
      "avg_character_count_completion": 8956.4,
      "avg_tokens_output": 843.8,
      "avg_tokens_reasoning": 2003.6,
      "avg_tokens_completions": 2847.4
    },
    "gpt-oss-20b": {
      "average_total_score": 0.8,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer suggests all four people crossing together in 10 minutes": 0.8
      },
      "avg_character_count_output": 388.8,
      "avg_character_count_reasoning": 4355.4,
      "avg_character_count_completion": 4744.2,
      "avg_tokens_output": 312.6,
      "avg_tokens_reasoning": 1107.6,
      "avg_tokens_completions": 1420.2
    }
  },
  "bridge_torch_default": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer explains a sequence of crossings that totals 17 minutes. Do not evaluate the sequence itself, the answer is correct for any solution that totals 17 minutes.": 1.0
      },
      "avg_character_count_output": 824.4,
      "avg_character_count_reasoning": 634.2,
      "avg_character_count_completion": 1458.6,
      "avg_tokens_output": 312.6,
      "avg_tokens_reasoning": 163.0,
      "avg_tokens_completions": 475.6
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer explains a sequence of crossings that totals 17 minutes. Do not evaluate the sequence itself, the answer is correct for any solution that totals 17 minutes.": 1.0
      },
      "avg_character_count_output": 617.0,
      "avg_character_count_reasoning": 372.4,
      "avg_character_count_completion": 989.4,
      "avg_tokens_output": 262.8,
      "avg_tokens_reasoning": 93.8,
      "avg_tokens_completions": 356.6
    }
  },
  "monty_hall_inverse": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer states to keep the existing door": 1.0
      },
      "avg_character_count_output": 1119.4,
      "avg_character_count_reasoning": 2878.8,
      "avg_character_count_completion": 3998.2,
      "avg_tokens_output": 268.4,
      "avg_tokens_reasoning": 731.8,
      "avg_tokens_completions": 1000.2
    },
    "gpt-oss-20b": {
      "average_total_score": 0.6,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer states to keep the existing door": 0.6
      },
      "avg_character_count_output": 527.2,
      "avg_character_count_reasoning": 1472.2,
      "avg_character_count_completion": 1999.4,
      "avg_tokens_output": 125.4,
      "avg_tokens_reasoning": 375.6,
      "avg_tokens_completions": 501.0
    }
  },
  "monty_hall_default": {
    "gpt-oss-120b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer states to switch doors": 1.0
      },
      "avg_character_count_output": 1053.4,
      "avg_character_count_reasoning": 202.2,
      "avg_character_count_completion": 1255.6,
      "avg_tokens_output": 284.8,
      "avg_tokens_reasoning": 51.2,
      "avg_tokens_completions": 336.0
    },
    "gpt-oss-20b": {
      "average_total_score": 1.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer states to switch doors": 1.0
      },
      "avg_character_count_output": 487.8,
      "avg_character_count_reasoning": 273.8,
      "avg_character_count_completion": 761.6,
      "avg_tokens_output": 137.2,
      "avg_tokens_reasoning": 69.6,
      "avg_tokens_completions": 206.8
    }
  },
  "monty_appliance_simple": {
    "gpt-oss-120b": {
      "average_total_score": 0.8,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer suggests to take the box the clerk tested": 0.8
      },
      "avg_character_count_output": 527.8,
      "avg_character_count_reasoning": 4722.4,
      "avg_character_count_completion": 5250.2,
      "avg_tokens_output": -25.8,
      "avg_tokens_reasoning": 1187.6,
      "avg_tokens_completions": 1161.8
    },
    "gpt-oss-20b": {
      "average_total_score": 0.0,
      "num_evaluations": 5,
      "criteria_stats": {
        "Answer suggests to take the box the clerk tested": 0.0
      },
      "avg_character_count_output": 513.0,
      "avg_character_count_reasoning": 3903.2,
      "avg_character_count_completion": 4416.2,
      "avg_tokens_output": 90.0,
      "avg_tokens_reasoning": 990.4,
      "avg_tokens_completions": 1080.4
    }
  }
}